"""Celery tasks for V2 story generation using GPT-4o Vision."""
import base64
import json
import logging
import uuid
from contextlib import contextmanager
from typing import Dict, Any, List, Optional
import httpx
from openai import OpenAI
from app.celery_app import celery_app
from app.database import get_session_local
from app.models.campaign import Campaign
from app.config import settings

logger = logging.getLogger(__name__)

# Constants
MAX_RETRIES = 2
RETRY_DELAY_BASE = 30

# ElevenLabs voice IDs for common voice styles
VOICE_ID_MAP = {
    "warm female": "pNInz6obpgDQGcFmaJgB",  # Alloy-like warm female
    "professional male": "VR6AewLTigWG4xSOukaG",  # Arnold-like deep male
    "young female": "EXAVITQu4vr4xnSDxMaL",  # Bella-like young female
    "calm male": "TxGEqnHWrfWFTfGW9XjX",  # Josh-like calm male
    "energetic female": "jBpfuIE2acCO8z3wKNLl",  # Gigi-like energetic
}

# System prompt for Step 1: Story Writing (GPT-4o Vision)
STORY_WRITING_SYSTEM = """You are an expert VIRAL AD creator. You make TikTok/Instagram Reels ads that get millions of views.

Your ads are FAST, PUNCHY, and ADDICTIVE. They hook in 1 second, not 3.

VIRAL AD FORMULA:
1. HOOK (0-2s): Pattern interrupt. Shock, curiosity, or instant relatability. "POV:", "Wait...", visual surprise
2. PROBLEM (2-8s): Amplify the pain. Make viewers FEEL it viscerally
3. SOLUTION (8-20s): App as the hero. Show it WORKING, not just existing
4. TRANSFORMATION (20-32s): Before/after energy shift. Joy, relief, success
5. CTA (32-40s): Urgency. "Link in bio", "Download now before..."

WHAT MAKES ADS VIRAL:
- Emotion over information (make them FEEL, not just understand)
- Specificity ("I saved 3 hours" > "save time")
- Pattern interrupts every 5-8 seconds
- Conversational, not corporate ("you know that feeling..." not "introducing...")
- Show, don't tell (character's face shows relief, not narrator saying "she felt relieved")

Output ONLY valid JSON in this exact format:
{
  "title": "Catchy 3-5 word hook/concept",
  "logline": "One punchy sentence that makes someone want to watch",
  "hook": "The exact opening line/visual that stops the scroll (under 10 words)",
  "full_narrative": "Full 40-second voiceover. Conversational, punchy, emotional. 90-110 words. Written exactly as it will be spoken - no stage directions.",
  "characters": [
    {
      "id": "main",
      "name": "Relatable name (Sarah, Mike, etc.)",
      "description": "ULTRA-SPECIFIC physical description for AI consistency: exact age (e.g., 28), ethnicity, hair color AND style AND length (e.g., shoulder-length wavy dark brown hair), eye color, skin tone, SPECIFIC outfit (e.g., cream oversized knit sweater, gold small hoop earrings), expression tendency (e.g., expressive eyebrows, warm smile). This EXACT description will be used in EVERY video frame.",
      "phone": "What phone they use (e.g., iPhone 15 Pro in natural titanium with clear case)"
    }
  ],
  "narrator": {
    "voice_style": "Describe the vibe (e.g., Your best friend telling you a secret, Excited older sister energy)",
    "tone": "2-3 descriptive words",
    "voice_category": "warm female"
  },
  "app_screens": [
    {
      "id": "screen_1",
      "description": "What this screen shows - the KEY feature that solves the problem"
    }
  ]
}

CRITICAL RULES:
- Character description will be COPIED VERBATIM into every video prompt. Be OBSESSIVELY specific.
- ONLY ONE main character (keep it simple for AI consistency)
- Character has ONE phone throughout. Specify the exact phone model and case.
- full_narrative is ONLY what the narrator says. No "[scene description]" or "(pause)" - just the words.
- voice_category must be one of: "warm female", "professional male", "young female", "calm male", "energetic female"
- Analyze screenshots to understand what the app ACTUALLY does, then show that specific value"""

# System prompt for Step 2: Story Segmentation (GPT-4o)
SEGMENTATION_SYSTEM = """You are an expert viral video editor creating a 40-second ad broken into 5 segments.

CRITICAL: These segments will be generated by AI video. PHYSICAL CONSISTENCY IS EVERYTHING.

Output ONLY valid JSON in this exact format:
{
  "segments": [
    {
      "number": 1,
      "voiceover": "EXACT words the narrator says. 18-22 words for 8 seconds. Conversational, punchy.",
      "visual": "What the viewer SEES. Describe the shot cinematically. Include character's exact appearance from the character description.",
      "action": "What MOVES in this shot. Character actions, camera movement. Be specific but SIMPLE.",
      "end_state": "EXACT description of the final frame - character position, expression, what's in frame. This MUST match the start of the next segment.",
      "app_screen": null or "Which app screen is shown ON the phone screen (not floating, ON the actual phone the character holds)"
    }
  ]
}

SEGMENT STRUCTURE:
- Segment 1 (0-8s): HOOK - Problem/pain point. Character frustrated/struggling. NO phone yet.
- Segment 2 (8-16s): DISCOVERY - Character picks up phone, opens app. Show app screen ON phone.
- Segment 3 (16-24s): USING - Character interacts with app. Show specific feature ON phone screen.
- Segment 4 (24-32s): TRANSFORMATION - Character's mood shifts. Relief, excitement, success.
- Segment 5 (32-40s): CTA - Happy character, maybe showing phone to camera. "Download now" energy.

PHYSICAL CONSISTENCY RULES (CRITICAL):
1. Character wears THE SAME outfit in ALL 5 segments. Copy the outfit description EXACTLY.
2. Character has ONE phone. Same phone in segments 2-5. Never two phones. Never phone disappears.
3. Setting should be consistent OR have clear transition (e.g., same room, or "later that day" at different location)
4. If character is sitting in segment 2, don't have them standing in segment 3 without showing them stand up.
5. Hair, accessories, jewelry - ALL must stay consistent.
6. end_state of segment N MUST logically connect to start of segment N+1

APP SCREEN RULES (CRITICAL):
- When showing the app, it appears ON the character's phone screen
- NOT floating next to them, NOT behind them, ON the phone they're holding
- Describe which specific app screen is shown (from app_screens list)
- Character should be LOOKING at the phone or SHOWING the phone to camera

VOICEOVER RULES:
- ONLY the exact words spoken. No stage directions.
- Split the full_narrative naturally across 5 segments
- Each ~18-22 words (8 seconds at conversational pace)
- Punchy, emotional, conversational - like talking to a friend

CAMERA/VISUAL RULES:
- Keep shots SIMPLE for AI video generation
- Avoid complex multi-person scenes
- Medium shots and close-ups work best
- One clear action per segment"""


@contextmanager
def db_session():
    """Context manager for database sessions with guaranteed cleanup."""
    db = get_session_local()()
    try:
        yield db
        db.commit()
    except Exception:
        db.rollback()
        raise
    finally:
        db.close()


def download_and_encode_image(image_url: str) -> Optional[str]:
    """Download image from URL and encode as base64.

    Args:
        image_url: URL of the image to download

    Returns:
        Base64 encoded string or None if failed
    """
    try:
        with httpx.Client(timeout=30.0) as client:
            response = client.get(image_url)
            response.raise_for_status()
            image_bytes = response.content
            return base64.b64encode(image_bytes).decode('utf-8')
    except Exception as e:
        logger.warning(f"Failed to download image | url={image_url[:60]}... | error={str(e)}")
        return None


def get_image_media_type(url: str) -> str:
    """Determine image media type from URL."""
    url_lower = url.lower()
    if '.png' in url_lower:
        return "image/png"
    elif '.gif' in url_lower:
        return "image/gif"
    elif '.webp' in url_lower:
        return "image/webp"
    return "image/jpeg"  # Default to JPEG


def step1_write_story(
    creative_bible: Dict[str, Any],
    app_screenshots: List[str],
    brand_name: str
) -> Dict[str, Any]:
    """Step 1: Generate full narrative using GPT-4o Vision.

    Args:
        creative_bible: Creative bible data with app info
        app_screenshots: List of app screenshot URLs
        brand_name: Name of the brand/app

    Returns:
        Story document with title, logline, narrative, characters, narrator
    """
    if not settings.OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY not configured")

    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    # Build user prompt with creative bible context
    app_name = creative_bible.get("app_name", brand_name)
    app_description = creative_bible.get("app_description", "")
    key_features = creative_bible.get("key_features", [])
    target_audience = creative_bible.get("target_audience", "")
    core_benefit = creative_bible.get("core_benefit", "")

    user_prompt = f"""Create a 40-second video ad for:

APP NAME: {app_name}
DESCRIPTION: {app_description}
KEY FEATURES: {', '.join(key_features) if isinstance(key_features, list) else key_features}
TARGET AUDIENCE: {target_audience}
CORE BENEFIT: {core_benefit}

I'm providing {len(app_screenshots)} app screenshots. Analyze them to understand the UI and incorporate accurate screen descriptions in your story.

Generate a compelling story that hooks viewers in the first 3 seconds, shows the app solving a real problem, and ends with a clear call-to-action."""

    # Build messages with images
    messages = [
        {"role": "system", "content": STORY_WRITING_SYSTEM},
    ]

    # Build content array with text and images
    content = [{"type": "text", "text": user_prompt}]

    # Add app screenshots as vision input (up to 5 images)
    for i, screenshot_url in enumerate(app_screenshots[:5]):
        # Try to use URL directly first, fall back to base64
        try:
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": screenshot_url,
                    "detail": "high"
                }
            })
            logger.info(f"Added screenshot {i+1} via URL | url={screenshot_url[:60]}...")
        except Exception:
            # Fallback to base64 encoding
            base64_image = download_and_encode_image(screenshot_url)
            if base64_image:
                media_type = get_image_media_type(screenshot_url)
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:{media_type};base64,{base64_image}",
                        "detail": "high"
                    }
                })
                logger.info(f"Added screenshot {i+1} via base64")

    messages.append({"role": "user", "content": content})

    # Call GPT-4o Vision
    logger.info(f"Calling GPT-4o Vision for story writing | screenshots={len(app_screenshots)}")

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        response_format={"type": "json_object"},
        temperature=0.8,
        max_tokens=2000
    )

    # Parse JSON response with error handling
    response_content = response.choices[0].message.content
    try:
        result = json.loads(response_content)
    except json.JSONDecodeError as e:
        logger.error(
            f"Failed to parse GPT-4o story response as JSON | error={str(e)} | "
            f"content={response_content[:300] if response_content else 'empty'}"
        )
        raise ValueError(f"Invalid JSON response from GPT-4o: {str(e)}")

    # Add ElevenLabs voice ID based on voice_category
    narrator = result.get("narrator", {})
    voice_category = narrator.get("voice_category", "warm female").lower()
    narrator["elevenlabs_voice_id"] = VOICE_ID_MAP.get(voice_category, VOICE_ID_MAP["warm female"])
    result["narrator"] = narrator

    # Add screenshot URLs to app_screens
    app_screens = result.get("app_screens", [])
    for i, screen in enumerate(app_screens):
        if i < len(app_screenshots):
            screen["url"] = app_screenshots[i]
    result["app_screens"] = app_screens

    logger.info(
        f"Story writing complete | title={result.get('title')} | "
        f"characters={len(result.get('characters', []))} | "
        f"narrative_words={len(result.get('full_narrative', '').split())}"
    )

    return result


def step2_segment_story(story: Dict[str, Any]) -> Dict[str, Any]:
    """Step 2: Break narrative into 5 segments using GPT-4o.

    Args:
        story: Story document from step 1

    Returns:
        Updated story document with segments array
    """
    if not settings.OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY not configured")

    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    # Build segmentation prompt with explicit character details
    characters = story.get('characters', [])
    main_char = characters[0] if characters else {}
    char_description = main_char.get('description', 'young professional')
    char_name = main_char.get('name', 'Character')
    char_phone = main_char.get('phone', 'smartphone')

    user_prompt = f"""Break this 40-second viral ad into exactly 5 segments of 8 seconds each.

FULL VOICEOVER SCRIPT:
{story.get('full_narrative', '')}

MAIN CHARACTER - {char_name}:
{char_description}
Phone: {char_phone}

⚠️ COPY THE ABOVE CHARACTER DESCRIPTION EXACTLY INTO EVERY SEGMENT'S "visual" FIELD.
The character MUST look identical in all 5 segments.

APP SCREENS AVAILABLE:
{json.dumps(story.get('app_screens', []), indent=2)}

HOOK/OPENING LINE:
{story.get('hook', '')}

Create 5 segments with PERFECT physical continuity. The end_state of each segment MUST match the start of the next.
- Segment 1: Hook/problem (NO phone)
- Segment 2: Discovers app (picks up phone, app visible ON screen)
- Segment 3: Uses app (interacting with specific feature ON phone)
- Segment 4: Transformation (mood shift, success)
- Segment 5: CTA (happy, maybe showing phone to camera)"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": SEGMENTATION_SYSTEM},
            {"role": "user", "content": user_prompt}
        ],
        response_format={"type": "json_object"},
        temperature=0.7,
        max_tokens=2000
    )

    # Parse JSON response with error handling
    response_content = response.choices[0].message.content
    try:
        segmentation = json.loads(response_content)
    except json.JSONDecodeError as e:
        logger.error(
            f"Failed to parse GPT-4o segmentation response as JSON | error={str(e)} | "
            f"content={response_content[:300] if response_content else 'empty'}"
        )
        raise ValueError(f"Invalid JSON response from GPT-4o segmentation: {str(e)}")

    # Merge segments into story document
    story["segments"] = segmentation.get("segments", [])

    logger.info(
        f"Story segmentation complete | segments={len(story.get('segments', []))}"
    )

    return story


def update_story_status(
    campaign_id: str,
    status: str,
    story_document: Optional[Dict[str, Any]] = None,
    error: Optional[str] = None
) -> bool:
    """Update story generation status in campaign."""
    try:
        with db_session() as db:
            campaign_uuid = uuid.UUID(campaign_id)
            campaign = db.query(Campaign).filter(Campaign.id == campaign_uuid).first()

            if not campaign:
                logger.error(f"Campaign not found | campaign={campaign_id}")
                return False

            campaign.pipeline_stage = f"story_{status}"

            if story_document:
                campaign.story_document = story_document
            if error:
                campaign.audio_generation_error = error  # Reuse existing error field

            logger.info(f"Story status updated | campaign={campaign_id} | status={status}")
            return True

    except Exception as e:
        logger.error(f"Failed to update story status | campaign={campaign_id} | error={str(e)}")
        return False


@celery_app.task(bind=True, max_retries=MAX_RETRIES, default_retry_delay=RETRY_DELAY_BASE)
def generate_story_task(self, campaign_id: str) -> Dict[str, Any]:
    """Generate story document for V2 pipeline.

    Two-step process:
    1. Story Writing (GPT-4o Vision) - Analyzes app screenshots, writes full narrative
    2. Segmentation (GPT-4o) - Breaks into 5 segments with actions and end states

    On completion, triggers:
    - voiceover_generation_task (parallel)
    - start_v2_image_generation (parallel)

    Args:
        campaign_id: Campaign UUID string

    Returns:
        Dict with status and story_document
    """
    logger.info(f"Starting story generation | campaign={campaign_id}")

    try:
        update_story_status(campaign_id, "generating")

        with db_session() as db:
            campaign_uuid = uuid.UUID(campaign_id)
            campaign = db.query(Campaign).filter(Campaign.id == campaign_uuid).first()

            if not campaign:
                logger.error(f"Campaign not found | campaign={campaign_id}")
                return {"status": "failed", "error": "Campaign not found"}

            # Get creative bible data
            creative_bible = {}
            if campaign.creative_bible:
                creative_bible = campaign.creative_bible.creative_bible or {}

            # Get app screenshots from campaign.images
            app_screenshots = []
            if campaign.images:
                app_screenshots = [
                    img.get("url") for img in campaign.images
                    if img.get("url")
                ]

            # Get brand name
            brand_name = campaign.brand.title if campaign.brand else "App"

            logger.info(
                f"Story generation inputs | campaign={campaign_id} | "
                f"brand={brand_name} | screenshots={len(app_screenshots)}"
            )

            # Check API key
            if not settings.OPENAI_API_KEY:
                error_msg = "OPENAI_API_KEY not configured"
                logger.error(f"{error_msg} | campaign={campaign_id}")
                update_story_status(campaign_id, "failed", error=error_msg)
                return {"status": "failed", "error": error_msg}

            # Step 1: Write story with GPT-4o Vision
            logger.info(f"Step 1: Writing story | campaign={campaign_id}")
            story = step1_write_story(creative_bible, app_screenshots, brand_name)

            # Step 2: Segment story
            logger.info(f"Step 2: Segmenting story | campaign={campaign_id}")
            story_document = step2_segment_story(story)

            # Save story document to campaign
            campaign.story_document = story_document
            campaign.pipeline_stage = "story_completed"
            campaign.pipeline_version = "v2p"
            db.commit()

            logger.info(
                f"Story generation complete | campaign={campaign_id} | "
                f"title={story_document.get('title')} | "
                f"segments={len(story_document.get('segments', []))}"
            )

            # Trigger next pipeline steps in parallel
            # 1. Voiceover generation
            from app.tasks.voiceover_generation import generate_voiceover_task
            generate_voiceover_task.delay(campaign_id)
            logger.info(f"Triggered voiceover generation | campaign={campaign_id}")

            # 2. Music generation (existing task)
            if settings.ELEVENLABS_API_KEY:
                from app.tasks.audio_generation import generate_audio_task
                generate_audio_task.delay(campaign_id)
                logger.info(f"Triggered music generation | campaign={campaign_id}")

            # 3. Video generation - use PARALLEL pipeline (Option B)
            # Much faster (~3 min vs ~15 min) with good consistency via reference images
            from app.tasks.parallel_video import start_parallel_pipeline_task
            start_parallel_pipeline_task.delay(campaign_id)
            logger.info(f"Triggered PARALLEL video pipeline | campaign={campaign_id}")

            return {
                "status": "completed",
                "campaign_id": campaign_id,
                "story_document": story_document
            }

    except Exception as e:
        error_msg = f"Story generation error: {str(e)}"
        logger.error(f"{error_msg} | campaign={campaign_id}", exc_info=True)

        # Retry if possible
        if self.request.retries < self.max_retries:
            retry_delay = RETRY_DELAY_BASE * (2 ** self.request.retries)
            logger.info(
                f"Retrying story generation ({self.request.retries + 1}/{self.max_retries}) | "
                f"campaign={campaign_id} | delay={retry_delay}s"
            )
            raise self.retry(exc=e, countdown=retry_delay)

        update_story_status(campaign_id, "failed", error=error_msg)
        return {"status": "failed", "error": error_msg}
